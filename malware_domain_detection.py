import requests
import json
import math
# Import thư viện re để sử dụng các biểu thức chính quy.
import re
# Import hàm urlparse từ thư viện urllib.parse để phân tích cú pháp URL.
from urllib.parse import urlparse
# Import CountVectorizer từ thư viện sklearn.feature_extraction.text để trích xuất đặc trưng từ văn bản.
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.neighbors import KNeighborsClassifier

# Khởi tạo biến domain với giá trị chuỗi rỗng.
domain = ''
# Khởi tạo biến domain_arr với giá trị danh sách rỗng.
domain_arr = []
# Khởi tạo biến path với giá trị chuỗi rỗng.
path = ''
# Khởi tạo biến path_arr với giá trị danh sách rỗng.
path_arr = []
# Khởi tạo biểu thức chính quy starts_with_http để kiểm tra xem một chuỗi có bắt đầu bằng "http" hay không.
starts_with_http = re.compile('^http')
# Khởi tạo biến j với giá trị từ điển rỗng.
j = {}
# Khởi tạo biến tlds với giá trị danh sách rỗng.
tlds = []
# Thiết lập biến file_name với tên tệp tin 'angler_domains.txt'.
file_name = 'angler_domains.txt'

def bigrams(input_list):
    # Nhận một danh sách input_list và trả về các cặp tuần tự gồm hai phần tử liên tiếp trong danh sách.
    return zip(input_list, input_list[1:])

def probability_score(word):
    score = 0
    # Kiểm tra nếu độ dài của từ nhỏ hơn 2, trả về score = 0.
    if len(word) < 2:
        return score

    # Gọi hàm bigrams để tạo ra các cặp ký tự từ từ word hiện tại và lưu vào biến b.
    b = bigrams(word)
    # Lặp qua từng cặp ký tự trong biến b.
    for char_tuple in b:
        # Ghép hai ký tự trong cặp thành một cặp ký tự và lưu vào biến pair.
        pair = char_tuple[0] + char_tuple[1]
        # Gán giá trị của khóa 'log' trong từ điển j cho biến tuple_lookup_value.
        try:
            tuple_lookup_value = j[pair]['log']
        # Nếu xảy ra lỗi KeyError (không tìm thấy khóa trong từ điển), gán tuple_lookup_value = -5.
        except KeyError:
            tuple_lookup_value = -5

        score = score + tuple_lookup_value
    return score

# Khai báo biến domain, domain_arr, path, path_arr, starts_with_http là biến toàn cục.
def parse_url(url):
    global domain
    global domain_arr
    global path
    global path_arr
    global starts_with_http

    #  Kiểm tra xem chuỗi url có bắt đầu bằng "http" hay không bằng cách áp dụng biểu thức chính quy starts_with_http lên chuỗi url và gán kết quả cho biến http_result.
    http_result = starts_with_http.match(url)
    if http_result:
        pass
    else:
        url = 'http://' + url

    # Phân tích cú pháp của chuỗi url bằng cách sử dụng hàm urlparse và gán kết quả cho biến u.
    u = urlparse(url)
    # Kiểm tra xem biến u có giá trị và có thuộc tính netloc hay không
    if u and u.netloc:
        domain = u.netloc
    else:
        print('Domain parse error')

    # Sử dụng biểu thức chính quy để loại bỏ chuỗi "www." từ biến domain.
    domain = re.sub('^www\.', '', domain)
    # Tách chuỗi domain thành các phần tử dựa trên dấu "." và lưu vào danh sách domain_arr.
    domain_arr = domain.split('.')

    # Gán giá trị của phần tử cuối cùng trong danh sách domain_arr cho biến tld.
    tld = domain_arr[-1]
    # Kiểm tra xem giá trị của tld có nằm trong danh sách tlds hay không.
    if tld in tlds:
        # Loại bỏ phần tử cuối cùng trong danh sách domain_arr.
        domain_arr.pop()
        # Ghép các phần tử trong danh sách domain_arr thành một chuỗi, cách nhau bởi dấu "." và gán kết quả cho biến domain.
        domain = '.'.join(domain_arr)

    # Tách chuỗi domain thành các phần tử dựa trên dấu "-" và dấu "." và lưu vào danh sách domain_arr.
    domain_arr = re.split('[-.]', domain)

    # Loại bỏ các phần tử rỗng trong danh sách domain_arr.
    domain_arr = list(filter(None, domain_arr))
    print('DOMAIN             ==> ', domain)
    # Gán giá trị của thuộc tính path của biến u cho biến path.
    if u and u.path:
        path = u.path
        # Tách chuỗi path thành các phần tử dựa trên dấu "/", "_", "." và "-" và lưu vào danh sách path_arr.
        path_arr = re.split('[/_.-]', path)
        #  Loại bỏ các phần tử rỗng trong danh sách path_arr.
        path_arr = list(filter(None, path_arr))
        print('PATH               ==> ', path)
    else:
        print('PATH               ==> No path info in URL')

    # Ghép danh sách domain_arr và path_arr thành một danh sách words.
    words = domain_arr + path_arr
    return words

# Hàm này nhận vào đầu vào là một danh sách các chuỗi data.
# Tạo một đối tượng CountVectorizer để chuyển đổi các chuỗi văn bản thành vectơ đếm.
# Sử dụng phương thức fit_transform của CountVectorizer để chuyển đổi danh sách data thành ma trận đặc trưng X.
# Trả về ma trận đặc trưng X.
def prepare_data(data):
    vectorizer = CountVectorizer()
    X = vectorizer.fit_transform(data)
    return X

def prepare_labels(labels):
    return labels

# Hàm này nhận vào ma trận đặc trưng X và danh sách nhãn y.
# Khởi tạo một đối tượng KNeighborsClassifier với n_neighbors=5 (số lượng láng giềng gần nhất).
# Sử dụng phương thức fit của KNeighborsClassifier để huấn luyện mô hình trên ma trận đặc trưng X và danh sách nhãn y.
# Trả về mô hình đã được huấn luyện.
def train_model(X, y):
    model = KNeighborsClassifier(n_neighbors=5)
    model.fit(X, y)
    return model

# Hàm này nhận vào mô hình phân loại model và một tên miền domain.
# Sử dụng hàm prepare_data để chuẩn bị dữ liệu cho tên miền domain và lưu vào biến X.
# Sử dụng mô hình model để dự đoán nhãn của X và lưu kết quả vào biến prediction.
# Trả về nhãn dự đoán đầu tiên trong danh sách prediction.
def classify_domain(model, domain):
    X = prepare_data([domain])
    prediction = model.predict(X)
    return prediction[0]

def main():
    global domain
    global domain_arr
    global path
    global path_arr
    global file_name
    global tlds
    global j
    # Đọc tệp tin JSON đã được tạo trước đó vào biến j.
    with open('character_pair_probabilities.json') as fi:
        j = json.load(fi)
    print('-- Read json --')

    # Gửi yêu cầu GET tới đường dẫn để lấy danh sách TLD mới nhất từ ICANN (Internet Corporation for Assigned Names and Numbers).
    r = requests.get('http://data.iana.org/TLD/tlds-alpha-by-domain.txt')
    # Chuyển đổi nội dung phản hồi thành chữ thường và chia thành mảng arr2.  
    arr2 = r.text.lower().split('\n')

    # Lấy một mảng con arr2[1:] từ mảng arr2 ban đầu chứa danh sách các TLD (Top-Level Domain) từ vị trí thứ 1 trở đi.
    tlds = arr2[1:]
    print('-- Fetched latest ICANN TLDs --\n')

    # read url
    with open(file_name, 'r') as fi:
        data = []
        labels = []
        # Đọc tất cả các dòng trong tệp tin đã mở (fi) và lưu vào danh sách urls.
        # Mỗi dòng trong tệp tin tương ứng với một URL.
        urls = fi.readlines()  
        for url in urls:
            # Thiết lập lại các biến domain, path, domain_arr và path_arr để đảm bảo chúng rỗng cho mỗi URL.
            domain = ''
            path = ''
            domain_arr = []
            path_arr = []
            # Chuyển đổi URL thành chữ thường và lưu vào biến url.
            url = url.rstrip().lower()
            print('URL                ==> ', url)
            words = parse_url(url)
            print('EVALUATING WORDS   ==> ', words)

            # Ghép các từ trong words thành một chuỗi và thêm vào danh sách data.
            data.append(' '.join(words))
            # Thêm nhãn 1 vào danh sách labels.
            labels.append(1)
            # Tính điểm tỷ lệ xác suất cho từng từ trong words bằng cách gọi hàm probability_score(word).
            for word in words:
                score = probability_score(word)
                malware_score = round(math.exp(abs(score)/len(word)), 3)
                # Nếu điểm tỷ lệ xác suất vượt qua ngưỡng 15, đặt nhãn 0 cho phần tử cuối cùng trong danh sách labels.
                if malware_score > 15:
                    labels[-1] = 0
                    print('Wrong word         ==> ', word)
                    print('Malware_score      ==> ', malware_score)
                    print('Classified as MALICIOUS')
                    print('\n')
                    break
                else :
                    print('Non-Malicious')     

if __name__ == "__main__":
    main()  